{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8eda019b8634d68bcae2211fe93afc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b910f87e8a74542b44d27ee776874da",
              "IPY_MODEL_a1bc0a42de4f48ccb9f41c3257395714",
              "IPY_MODEL_c03db8a7b24a46889599a2561127ef9c"
            ],
            "layout": "IPY_MODEL_fb3183e2ac22457ab7681da18eb00d6b"
          }
        },
        "0b910f87e8a74542b44d27ee776874da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd965bad2fa42918ab24a3536d714bf",
            "placeholder": "​",
            "style": "IPY_MODEL_53446b30b55142d490177844f1471b30",
            "value": "100%"
          }
        },
        "a1bc0a42de4f48ccb9f41c3257395714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86def824b9334c7491f61990caede347",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e39b9e61cfcd4d90868947d00c057806",
            "value": 1000
          }
        },
        "c03db8a7b24a46889599a2561127ef9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547118e57dc747ef8b1831a4eb25e790",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1942b92fee42f8b57e34d056c3b7ca",
            "value": " 1000/1000 [00:36&lt;00:00, 32.02it/s]"
          }
        },
        "fb3183e2ac22457ab7681da18eb00d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd965bad2fa42918ab24a3536d714bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53446b30b55142d490177844f1471b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86def824b9334c7491f61990caede347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39b9e61cfcd4d90868947d00c057806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "547118e57dc747ef8b1831a4eb25e790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1942b92fee42f8b57e34d056c3b7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRRcWAtsGNEd",
        "outputId": "f76d60b9-b41f-49cd-f533-ea116818979b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.4/265.4 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.4/385.4 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for twint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for googletransx (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --quiet twint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import twint"
      ],
      "metadata": {
        "id": "QQI0VOw_GxWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --quiet snscrape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOfUt6ACIMyO",
        "outputId": "e6c9efe5-2152-443a-ee0c-d2ce711dea2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.8 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import datetime\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_theme(style='whitegrid')"
      ],
      "metadata": {
        "id": "CMf0lw2lIQP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input('Enter query text to be matched (or leave it blank by pressing enter)') \n",
        "\n",
        "username = input('Enter specific username(s) from a twitter account without @ (or leave it blank by pressing enter): ') \n",
        "\n",
        "since = input('Enter startdate in this format yyyy-mm-dd (or leave it blank by pressing enter): ') \n",
        "\n",
        "until = input('Enter enddate in this format yyyy-mm-dd (or leave it blank by pressing enter): ') \n",
        "\n",
        "count = int(input('Enter max number of tweets or enter -1 to retrieve all possible tweets: ')) \n",
        "\n",
        "retweet = input('Exclude Retweets? (y/n): ') \n",
        "\n",
        "replies = input('Exclude Replies? (y/n): ') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfPAwu6uJWuc",
        "outputId": "427b4d99-65a6-4b57-b6da-0c7a35cc0da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter query text to be matched (or leave it blank by pressing enter)cybercrime\n",
            "Enter specific username(s) from a twitter account without @ (or leave it blank by pressing enter): \n",
            "Enter startdate in this format yyyy-mm-dd (or leave it blank by pressing enter): 2022-01-01\n",
            "Enter enddate in this format yyyy-mm-dd (or leave it blank by pressing enter): 2022-01-10\n",
            "Enter max number of tweets or enter -1 to retrieve all possible tweets: 1000\n",
            "Exclude Retweets? (y/n): y\n",
            "Exclude Replies? (y/n): y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search(text, username, since, until, retweet, replies):\n",
        "    global filename\n",
        "    q = text\n",
        "    if username != '':\n",
        "        q += f\" from:{username}\"\n",
        "    if until == '':\n",
        "        until = datetime.datetime.strftime(datetime.date.today(), '%Y-%m-%d')\n",
        "    q += f\" until:{until}\"\n",
        "    if since == '':\n",
        "        since = datetime.datetime.strftime(datetime.datetime.strptime(until, '%Y-%m-%d') - datetime.timedelta(days=7), '%Y-%m-%d')\n",
        "    q += f\" since:{since}\"\n",
        "    if retweet == 'y':\n",
        "        q += f\" exclude:retweets\"\n",
        "    if replies == 'y':\n",
        "        q += f\" exclude:replies\"\n",
        "    if username != '' and text != '':\n",
        "        filename = f\"{since}_{until}_{username}_{text}.csv\"\n",
        "    elif username != \"\":\n",
        "        filename = f\"{since}_{until}_{username}.csv\"\n",
        "    else:\n",
        "        filename = f\"{since}_{until}_{text}.csv\"\n",
        "    print(filename)\n",
        "    return q"
      ],
      "metadata": {
        "id": "0RSVzcRcIkfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = search(text, username, since, until, retweet, replies)\n",
        "\n",
        "# Creating list to append tweet data\n",
        "tweets_list1 = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "if count == -1:\n",
        "    for i, tweet in enumerate(tqdm_notebook(sntwitter.TwitterSearchScraper(q).get_items())):\n",
        "        tweets_list1.append([\n",
        "            tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.lang,\n",
        "            tweet.hashtags, tweet.replyCount, tweet.retweetCount, tweet.likeCount,\n",
        "            tweet.quoteCount, tweet.media\n",
        "        ])\n",
        "else:\n",
        "    with tqdm_notebook(total=count) as pbar:\n",
        "        for i, tweet in enumerate(sntwitter.TwitterSearchScraper(q).get_items()): \n",
        "            # declare a username\n",
        "            if i >= count: # number of tweets you want to scrape\n",
        "                break\n",
        "            tweets_list1.append([\n",
        "                tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.lang,\n",
        "                tweet.hashtags, tweet.replyCount, tweet.retweetCount, tweet.likeCount,\n",
        "                tweet.quoteCount, tweet.media\n",
        "            ])\n",
        "            pbar.update(1)\n",
        "\n",
        "# Creating a dataframe from the tweets list above\n",
        "tweets_df1 = pd.DataFrame(tweets_list1, columns=['DateTime', 'TweetId', 'Text', 'Username', 'Language',\n",
        "                                                 'Hashtags', 'ReplyCount', 'RetweetCount',\n",
        "                                                 'LikeCount', 'QuoteCount', 'Media'])"
      ],
      "metadata": {
        "id": "s4QepLx3JPVX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b8eda019b8634d68bcae2211fe93afc2",
            "0b910f87e8a74542b44d27ee776874da",
            "a1bc0a42de4f48ccb9f41c3257395714",
            "c03db8a7b24a46889599a2561127ef9c",
            "fb3183e2ac22457ab7681da18eb00d6b",
            "3dd965bad2fa42918ab24a3536d714bf",
            "53446b30b55142d490177844f1471b30",
            "86def824b9334c7491f61990caede347",
            "e39b9e61cfcd4d90868947d00c057806",
            "547118e57dc747ef8b1831a4eb25e790",
            "ad1942b92fee42f8b57e34d056c3b7ca"
          ]
        },
        "outputId": "57e29838-2255-4775-b08b-64cefd0ab6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-01_2022-01-10_cybercrime.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8eda019b8634d68bcae2211fe93afc2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tw_df = tweets_df1.sort_values(by='DateTime',ascending=False) \n",
        "tw_df.tail()"
      ],
      "metadata": {
        "id": "5nieVd5kJRhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "f455c05b-181c-46d7-cef5-c4027104fa2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     DateTime              TweetId  \\\n",
              "995 2022-01-07 06:19:26+00:00  1479336860082073600   \n",
              "996 2022-01-07 06:14:54+00:00  1479335719696879617   \n",
              "997 2022-01-07 06:14:38+00:00  1479335651732430850   \n",
              "998 2022-01-07 06:12:01+00:00  1479334991146504193   \n",
              "999 2022-01-07 06:09:30+00:00  1479334360507576321   \n",
              "\n",
              "                                                  Text         Username  \\\n",
              "995  लड़की कर रही थी लड़की को डेट, जब खुलासा हुआ तो...           aajtak   \n",
              "996  FortiGuard Labs Prediksi Serangan Siber pada T...        TechforID   \n",
              "997  Conducted awareness on Cyber Crime, Traffic Ru...        pskkp_cyb   \n",
              "998  Some simple and useful tips on identifying a P...  celminestrategy   \n",
              "999  Cyber Crime &amp; Digital Evidence [Indian Per...      busicat_adv   \n",
              "\n",
              "    Language                                           Hashtags  ReplyCount  \\\n",
              "995       hi                         [cybercrime, onlinedating]           4   \n",
              "996       in  [FortiGuardLabs, SeranganSiber, CyberCrime, Cy...           1   \n",
              "997       en                                               None           2   \n",
              "998       en  [Phishing, CyberCrime, OnlineSafety, Informati...           0   \n",
              "999       en                                               None           0   \n",
              "\n",
              "     RetweetCount  LikeCount  QuoteCount  \\\n",
              "995             3         57           1   \n",
              "996             3          1           0   \n",
              "997             7         67           0   \n",
              "998             2          2           0   \n",
              "999             0          0           0   \n",
              "\n",
              "                                                 Media  \n",
              "995                                               None  \n",
              "996                                               None  \n",
              "997  [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
              "998  [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
              "999  [Photo(previewUrl='https://pbs.twimg.com/media...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e142d4d6-272b-454f-9264-98e629fc8b28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DateTime</th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Username</th>\n",
              "      <th>Language</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>ReplyCount</th>\n",
              "      <th>RetweetCount</th>\n",
              "      <th>LikeCount</th>\n",
              "      <th>QuoteCount</th>\n",
              "      <th>Media</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2022-01-07 06:19:26+00:00</td>\n",
              "      <td>1479336860082073600</td>\n",
              "      <td>लड़की कर रही थी लड़की को डेट, जब खुलासा हुआ तो...</td>\n",
              "      <td>aajtak</td>\n",
              "      <td>hi</td>\n",
              "      <td>[cybercrime, onlinedating]</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>2022-01-07 06:14:54+00:00</td>\n",
              "      <td>1479335719696879617</td>\n",
              "      <td>FortiGuard Labs Prediksi Serangan Siber pada T...</td>\n",
              "      <td>TechforID</td>\n",
              "      <td>in</td>\n",
              "      <td>[FortiGuardLabs, SeranganSiber, CyberCrime, Cy...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>2022-01-07 06:14:38+00:00</td>\n",
              "      <td>1479335651732430850</td>\n",
              "      <td>Conducted awareness on Cyber Crime, Traffic Ru...</td>\n",
              "      <td>pskkp_cyb</td>\n",
              "      <td>en</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>2022-01-07 06:12:01+00:00</td>\n",
              "      <td>1479334991146504193</td>\n",
              "      <td>Some simple and useful tips on identifying a P...</td>\n",
              "      <td>celminestrategy</td>\n",
              "      <td>en</td>\n",
              "      <td>[Phishing, CyberCrime, OnlineSafety, Informati...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>2022-01-07 06:09:30+00:00</td>\n",
              "      <td>1479334360507576321</td>\n",
              "      <td>Cyber Crime &amp;amp; Digital Evidence [Indian Per...</td>\n",
              "      <td>busicat_adv</td>\n",
              "      <td>en</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e142d4d6-272b-454f-9264-98e629fc8b28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e142d4d6-272b-454f-9264-98e629fc8b28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e142d4d6-272b-454f-9264-98e629fc8b28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "# keyword pencarian tweet\n",
        "keyword = \"data breach\"\n",
        "\n",
        "# tanggal awal dan akhir pencarian tweet\n",
        "since_date = \"2022-03-01\"\n",
        "until_date = \"2022-03-02\"\n",
        "\n",
        "# list untuk menyimpan data tweet\n",
        "tweets_list = []\n",
        "\n",
        "# melakukan scraping tweet\n",
        "for tweet in sntwitter.TwitterSearchScraper(keyword + f\" since:{since_date} until:{until_date}\").get_items():\n",
        "    # menyimpan data tweet yang diperlukan\n",
        "    tweet_dict = {\n",
        "        'date': tweet.date.strftime('%Y-%m-%d'),\n",
        "        'id': tweet.id,\n",
        "        'content': tweet.rawContent,\n",
        "        'user': tweet.user.username,\n",
        "        'url': tweet.url,\n",
        "        'reply_count': tweet.replyCount,\n",
        "        'retweet_count': tweet.retweetCount,\n",
        "        'like_count': tweet.likeCount\n",
        "    }\n",
        "    tweets_list.append(tweet_dict)\n",
        "\n",
        "# mengubah list tweet menjadi dataframe\n",
        "tweets_df = pd.DataFrame(tweets_list)\n",
        "\n",
        "# menampilkan 10 tweet teratas\n",
        "print(tweets_df.head(10))\n"
      ],
      "metadata": {
        "id": "wzoz_Y4pD-co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.tail()"
      ],
      "metadata": {
        "id": "nb35Yx4WHZu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "id": "c1jZeYpjILFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "\n",
        "max_tweets = 50\n",
        "search_words = \"data breach\"\n",
        "\n",
        "tweets = []\n",
        "\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_words + ' lang:en since:2020-01-01 until:2021-01-01').get_items()):\n",
        "    if i>max_tweets:\n",
        "        break\n",
        "    tweets.append({'date': tweet.date, 'content': tweet.rawContent})\n",
        "\n",
        "tweets = pd.DataFrame(tweets)\n",
        "\n",
        "# menampilkan 10 tweet teratas\n",
        "tweets.head(10)"
      ],
      "metadata": {
        "id": "0AgBhzxIN34x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Load dataset\n",
        "df = tweets\n",
        "\n",
        "# Remove URLs, mentions, and hashtags\n",
        "df['cleaned_text'] = df['content'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
        "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: re.sub(r\"@\\S+\", \"\", x))\n",
        "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: re.sub(r\"#\\S+\", \"\", x))\n",
        "\n",
        "# Convert text to lowercase\n",
        "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: x.lower())\n",
        "\n",
        "# Tokenize text\n",
        "df['tokenized_text'] = df['cleaned_text'].apply(lambda x: word_tokenize(x))\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['filtered_text'] = df['tokenized_text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# Lemmatize text\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['lemmatized_text'] = df['filtered_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "# Save preprocessed data\n",
        "df.to_csv('preprocessed_tweet_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "fgcZJ7U8Hxh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = pd.read_csv('preprocessed_tweet_data.csv')\n",
        "dfs.tail()"
      ],
      "metadata": {
        "id": "L7hVbgzsJuDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('preprocessed_tweet_data.csv')\n",
        "\n",
        "# Buat kolom baru untuk menyimpan hasil anotasi\n",
        "df['annotated_data'] = ''\n",
        "\n",
        "# Lakukan anotasi\n",
        "for index, row in df.iterrows():\n",
        "    print(row['cleaned_text'])\n",
        "    label = input(\"Label: \")\n",
        "    df.at[index, 'label'] = label\n",
        "    \n",
        "# Simpan hasil anotasi ke dalam file CSV\n",
        "df.to_csv('annotated_tweet_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "ZclITiy3JLwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfa = pd.read_csv('annotated_tweet_data.csv')\n",
        "dfa.head()"
      ],
      "metadata": {
        "id": "qvX3DWDzSCwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfa = dfa.rename(columns={'content': 'tweet'})\n",
        "dfa.head()\n"
      ],
      "metadata": {
        "id": "4w43yBmMUORQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "\n",
        "# Tokenize text and remove stop words\n",
        "corpus = dfa['tweet'].tolist()\n",
        "tokens = [word_tokenize(text.lower()) for text in corpus]\n",
        "filtered_tokens = [[word for word in token if word not in stop_words] for token in tokens]\n",
        "filtered_corpus = [' '.join(token) for token in filtered_tokens]\n",
        "\n",
        "# Extract features using Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(filtered_corpus)\n",
        "y = dfa['label'].tolist()\n",
        "\n",
        "print(X.toarray())\n",
        "print(y)"
      ],
      "metadata": {
        "id": "uthSeOkfSxBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Split dataset into training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1 Score: \", f1)\n",
        "\n",
        "# Print classification report\n",
        "#print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "x5h3Xbf5VsXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ],
      "metadata": {
        "id": "K9kbnRS-YcRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Split dataset into training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model using Multinomial Naive Bayes\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict using testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate model using confusion matrix and classification report\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Evaluate model using k-fold cross validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(clf, X, y, cv=kfold)\n",
        "print(\"Cross validation scores: \", scores)\n",
        "print(\"Average cross validation score: \", np.mean(scores))\n"
      ],
      "metadata": {
        "id": "MGRa53k0Y6lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load test dataset\n",
        "test_df = pd.read_csv('annotated_tweet_data.csv')\n",
        "\n",
        "# Tokenize text and remove stop words\n",
        "test_corpus = test_df['content'].tolist()\n",
        "test_tokens = [word_tokenize(text.lower()) for text in test_corpus]\n",
        "test_filtered_tokens = [[word for word in token if word not in stop_words] for token in test_tokens]\n",
        "test_filtered_corpus = [' '.join(token) for token in test_filtered_tokens]\n",
        "\n",
        "# Extract features using Bag of Words\n",
        "test_X = vectorizer.transform(test_filtered_corpus)\n",
        "test_y = test_df['label'].tolist()\n",
        "\n",
        "# Predict on test dataset\n",
        "test_y_pred = clf.predict(test_X)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_y, test_y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "id": "jDJZLGbfalDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Load stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Load dataset from csv file\n",
        "df = pd.read_csv('annotated_tweet_data.csv')\n",
        "\n",
        "# Tokenize text and remove stop words\n",
        "corpus = df['content'].tolist()\n",
        "tokens = [word_tokenize(text.lower()) for text in corpus]\n",
        "filtered_tokens = [[word for word in token if word not in stop_words] for token in tokens]\n",
        "filtered_corpus = [' '.join(token) for token in filtered_tokens]\n",
        "\n",
        "# Extract features using Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(filtered_corpus)\n",
        "y = df['label'].tolist()\n",
        "\n",
        "# Train model\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "new_text = ['The users as a whole, not the individual. So I can be harmed if someone else falls for this malicious attack. It is similar to when Google has a databreach, compromising several thousands of accounts at once.']\n",
        "new_tokens = [word_tokenize(text.lower()) for text in new_text]\n",
        "new_filtered_tokens = [[word for word in token if word not in stop_words] for token in new_tokens]\n",
        "new_filtered_corpus = [' '.join(token) for token in new_filtered_tokens]\n",
        "new_X = vectorizer.transform(new_filtered_corpus)\n",
        "\n",
        "prediction = clf.predict(new_X)\n",
        "\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "id": "6zOfKCurb-3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Load stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Load dataset from csv file\n",
        "df = pd.read_csv('annotated_tweet_data.csv')\n",
        "\n",
        "# Tokenize text and remove stop words\n",
        "corpus = df['content'].tolist()\n",
        "tokens = [word_tokenize(text.lower()) for text in corpus]\n",
        "filtered_tokens = [[word for word in token if word not in stop_words] for token in tokens]\n",
        "filtered_corpus = [' '.join(token) for token in filtered_tokens]\n",
        "\n",
        "# Extract features using Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(filtered_corpus)\n",
        "y = df['label'].tolist()\n",
        "\n",
        "# Train model\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "new_text = ['The users as a whole, not the individual. So I can be harmed if someone else falls for this malicious attack. It is similar to when Google has a databreach, compromising several thousands of accounts at once.'\n",
        "            , 'I received a check of 17 dollars from the Equifax data breach settlement and it bounced because they used SIGNATURE BANK.'\n",
        "            , 'I am monitoring the data breach hotline this week ama'\n",
        "            , 'LockBit Ransomware Claims Data Breach at SpaceX Contractor. Hackers News'\n",
        "            , 'Students in the Los Angeles school district faced a data breach last year, but now, hackers are taking mental health problems to a new level by selling off the data to buyers on the #darkweb.'\n",
        "            , '@DPCIreland⁩ Can you please get someone in your office to respond to my e-mails in relation to a possible Data Breach'\n",
        "            ]\n",
        "new_tokens = [word_tokenize(text.lower()) for text in new_text]\n",
        "new_filtered_tokens = [[word for word in token if word not in stop_words] for token in new_tokens]\n",
        "new_filtered_corpus = [' '.join(token) for token in new_filtered_tokens]\n",
        "new_X = vectorizer.transform(new_filtered_corpus)\n",
        "\n",
        "# Predict and print results\n",
        "prediction = clf.predict(new_X)\n",
        "\n",
        "# Create pandas dataframe to store the results\n",
        "results_df = pd.DataFrame({'Text': new_text, 'Label': prediction})\n",
        "\n",
        "# Add column for label name\n",
        "label_names = {0: 'Non-Attack', 1: 'Attack', 2: 'Neutral'}\n",
        "results_df['Category'] = results_df['Label'].map(label_names)\n",
        "\n",
        "results_df\n"
      ],
      "metadata": {
        "id": "tScski-EddK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test2\n"
      ],
      "metadata": {
        "id": "LJCPCypBUpv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet snscrape"
      ],
      "metadata": {
        "id": "tB79BediUtEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d452db8c-0c15-4f84-9c30-3d46a9e03c29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.8 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --quiet scikit-learn"
      ],
      "metadata": {
        "id": "SLc0tfSU7YZ_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet scikit-learn pandas numpy"
      ],
      "metadata": {
        "id": "IwPngE5e84o8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "ew92DTaRdGHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbe1656-a6c9-43a5-def1-4f3f3af4f1fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan keyword dan tanggal pencarian\n",
        "keyword = \"pelayanan bank bri\"\n",
        "since_date = \"2022-01-01\"\n",
        "until_date = \"2023-01-01\"\n",
        "\n",
        "# Buat query pencarian\n",
        "query = f\"{keyword} since:{since_date} until:{until_date} lang:id\"\n",
        "\n",
        "# Scraping tweet dengan snscrape\n",
        "tweets = []\n",
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
        "    tweets.append([tweet.date, tweet.rawContent, tweet.user.username, tweet.likeCount, tweet.replyCount, tweet.retweetCount])\n",
        "    if i >= 10000:\n",
        "        break\n",
        "\n",
        "# Simpan hasil scraping ke dalam dataframe\n",
        "df = pd.DataFrame(tweets, columns=[\"Tanggal\", \"Tweet\", \"Username\", \"Likes\", \"Replies\", \"Retweets\"])\n"
      ],
      "metadata": {
        "id": "v83Vh4k6U10e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan dataset dengan kolom sentimen baru\n",
        "df.to_csv(\"data.csv\", index=False)"
      ],
      "metadata": {
        "id": "pZcIJFLz0Ofi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "xn45KeBk92gl",
        "outputId": "00d6080d-c849-4e69-d4c9-b888cb512455"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Tanggal  \\\n",
              "1158 2022-01-10 04:26:17+00:00   \n",
              "1159 2022-01-04 03:59:03+00:00   \n",
              "1160 2022-01-03 06:26:10+00:00   \n",
              "1161 2022-01-03 03:33:51+00:00   \n",
              "1162 2022-01-03 00:49:13+00:00   \n",
              "\n",
              "                                                  Tweet       Username  Likes  \\\n",
              "1158  Bca emang terbaik dalam pelayanan, tapi dari s...      Thebensky      0   \n",
              "1159  Ke @BANKBRI_ID cab Cilandak KKO di handle deng...      nyanyu_id      0   \n",
              "1160  Personil Satuan Samapta Polres Nunukan melaksa...  PolresNunukan      0   \n",
              "1161  @BANKBRI_ID @kontakBRI Mohon untuk ditingkatka...       Darto001      0   \n",
              "1162  @BANKBRI_ID Semoga beruntung aamiin \\nPelayana...        AkuuXrc      0   \n",
              "\n",
              "      Replies  Retweets  \n",
              "1158        0         0  \n",
              "1159        3         0  \n",
              "1160        0         0  \n",
              "1161        7         0  \n",
              "1162        0         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-239f5725-5192-4396-9582-0d70c23538eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tanggal</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Username</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Replies</th>\n",
              "      <th>Retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>2022-01-10 04:26:17+00:00</td>\n",
              "      <td>Bca emang terbaik dalam pelayanan, tapi dari s...</td>\n",
              "      <td>Thebensky</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>2022-01-04 03:59:03+00:00</td>\n",
              "      <td>Ke @BANKBRI_ID cab Cilandak KKO di handle deng...</td>\n",
              "      <td>nyanyu_id</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>2022-01-03 06:26:10+00:00</td>\n",
              "      <td>Personil Satuan Samapta Polres Nunukan melaksa...</td>\n",
              "      <td>PolresNunukan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1161</th>\n",
              "      <td>2022-01-03 03:33:51+00:00</td>\n",
              "      <td>@BANKBRI_ID @kontakBRI Mohon untuk ditingkatka...</td>\n",
              "      <td>Darto001</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>2022-01-03 00:49:13+00:00</td>\n",
              "      <td>@BANKBRI_ID Semoga beruntung aamiin \\nPelayana...</td>\n",
              "      <td>AkuuXrc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-239f5725-5192-4396-9582-0d70c23538eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-239f5725-5192-4396-9582-0d70c23538eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-239f5725-5192-4396-9582-0d70c23538eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk melakukan preprocessing\n",
        "def preprocess_tweet(tweet):\n",
        "    # Menghapus tanda baca dan karakter khusus\n",
        "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "\n",
        "    # Mengubah ke huruf kecil\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # Menghapus stopwords\n",
        "    stop_words = set(stopwords.words('indonesian'))\n",
        "    tokens = nltk.word_tokenize(tweet)\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    # Melakukan lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Menggabungkan kembali token menjadi kalimat\n",
        "    tweet = ' '.join(tokens)\n",
        "    return tweet\n",
        "\n",
        "# Preprocessing pada kolom Tweet dalam DataFrame\n",
        "df['Tweet'] = df['Tweet'].apply(preprocess_tweet)\n"
      ],
      "metadata": {
        "id": "9e4klxVA5gQ8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Fungsi untuk mendapatkan sentimen dari tweet\n",
        "def get_sentiment(tweet):\n",
        "    sentiment = TextBlob(tweet).sentiment.polarity\n",
        "    if sentiment > 0:\n",
        "        return 'positif'\n",
        "    elif sentiment < 0:\n",
        "        return 'negatif'\n",
        "    else:\n",
        "        return 'netral'\n",
        "\n",
        "# Menentukan label sentimen untuk setiap tweet\n",
        "df['Sentiment'] = df['Tweet'].apply(get_sentiment)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "ymzNbjLj6TYY",
        "outputId": "87da85df-2e79-4ad2-b27e-1f001df52c14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Tanggal  \\\n",
              "0 2022-12-31 18:51:16+00:00   \n",
              "1 2022-12-29 04:47:45+00:00   \n",
              "2 2022-12-27 07:43:58+00:00   \n",
              "3 2022-12-26 10:38:50+00:00   \n",
              "4 2022-12-26 07:07:18+00:00   \n",
              "\n",
              "                                               Tweet        Username  Likes  \\\n",
              "0  kontakbri bankbri_id promo_bri bank bumn pelay...  RaffaDwiputtra      0   \n",
              "1  bankbri_id spallpilllll min saran gak kalo lho...          KiKYyy      1   \n",
              "2  gandeng bank bri rutan 1 medan maksimalkan pel...     rutan1medan      0   \n",
              "3  poetra1804 informasikan jam operasional bank b...      BANKBRI_ID      1   \n",
              "4  kontakbri siangsiang darah c bri unit buludoan...     AsbudiAswan      3   \n",
              "\n",
              "   Replies  Retweets Sentiment  \n",
              "0        1         0   positif  \n",
              "1        4         0    netral  \n",
              "2        0         0    netral  \n",
              "3        1         0    netral  \n",
              "4       13         0    netral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d44b4c9f-038a-422c-bd2b-8310fc24b2ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tanggal</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Username</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Replies</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-12-31 18:51:16+00:00</td>\n",
              "      <td>kontakbri bankbri_id promo_bri bank bumn pelay...</td>\n",
              "      <td>RaffaDwiputtra</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-12-29 04:47:45+00:00</td>\n",
              "      <td>bankbri_id spallpilllll min saran gak kalo lho...</td>\n",
              "      <td>KiKYyy</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>netral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-12-27 07:43:58+00:00</td>\n",
              "      <td>gandeng bank bri rutan 1 medan maksimalkan pel...</td>\n",
              "      <td>rutan1medan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>netral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-12-26 10:38:50+00:00</td>\n",
              "      <td>poetra1804 informasikan jam operasional bank b...</td>\n",
              "      <td>BANKBRI_ID</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>netral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-12-26 07:07:18+00:00</td>\n",
              "      <td>kontakbri siangsiang darah c bri unit buludoan...</td>\n",
              "      <td>AsbudiAswan</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>netral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d44b4c9f-038a-422c-bd2b-8310fc24b2ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d44b4c9f-038a-422c-bd2b-8310fc24b2ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d44b4c9f-038a-422c-bd2b-8310fc24b2ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"sentimented_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "Zh5kGrTP-IBm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat vektor fitur menggunakan CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df['Tweet'])\n",
        "\n",
        "# Menentukan target\n",
        "y = df['Sentiment']\n",
        "\n",
        "# Membagi data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Membuat model Naive Bayes Classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Melakukan prediksi pada data uji\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Menghitung akurasi\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30FWMvhh53xV",
        "outputId": "2ae6dffa-e0ae-4d7b-9e9a-1b7b3c85f0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi: 0.922077922077922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Membuat model SVM\n",
        "svm_model = SVC(kernel='linear', probability=True)\n",
        "\n",
        "# Membuat model Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Menggabungkan kedua model dalam voting classifier\n",
        "voting_model = VotingClassifier(estimators=[('svm', svm_model), ('nb', nb_model)], voting='soft')\n",
        "\n",
        "# Melatih model pada data training\n",
        "voting_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "gvucdGgw7qJP",
        "outputId": "db4172bc-e190-43de-e511-f7cc97a06bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('svm', SVC(kernel='linear', probability=True)),\n",
              "                             ('nb', MultinomialNB())],\n",
              "                 voting='soft')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;svm&#x27;, SVC(kernel=&#x27;linear&#x27;, probability=True)),\n",
              "                             (&#x27;nb&#x27;, MultinomialNB())],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;svm&#x27;, SVC(kernel=&#x27;linear&#x27;, probability=True)),\n",
              "                             (&#x27;nb&#x27;, MultinomialNB())],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>nb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v05K2_Iq9Nof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Melakukan prediksi sentimen pada data testing\n",
        "y_pred = voting_model.predict(X_test)\n",
        "\n",
        "# Menghitung akurasi prediksi\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Akurasi prediksi: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loO94QnC7wtP",
        "outputId": "50685f05-15ae-4825-8d75-9754ac9f8c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi prediksi: 0.958041958041958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi sentimen pada data baru\n",
        "new_tweet = \"Di RSX tmpatku dari 8 pasien covid19, yg 6 mninggal sbb diracuni. Stlah minum obat kansgung mulut berbusa. Lalu gk lama kmudian tahu2 dibawain keranda mayat. Yg dua lagi brontak.  Gn mo nelen obat. Dn slama sampai kini...\"\n",
        "new_tweet = preprocess_tweet(new_tweet)\n",
        "X_test = vectorizer.transform([new_tweet])\n",
        "y_pred = voting_model.predict(X_test)\n",
        "\n",
        "# Cetak hasil prediksi\n",
        "print(\"Hasil prediksi sentimen:\")\n",
        "print(\"Sentimen: \", y_pred[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtzLHBu_0NgF",
        "outputId": "4976c86b-958a-4e62-ae5a-50ed81aa6d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil prediksi sentimen:\n",
            "Sentimen:  netral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tweet(tweet):\n",
        "    # Menghapus karakter non-angka/non-huruf\n",
        "    tweet = re.sub('[^a-zA-Z0-9]', ' ', tweet)\n",
        "    # Mengubah semua huruf menjadi lowercase\n",
        "    tweet = tweet.lower()\n",
        "    return tweet\n",
        "\n",
        "# Menerapkan preprocessing pada tweet\n",
        "df['Tweet'] = df['Tweet'].apply(preprocess_tweet)\n",
        "\n",
        "# Membagi dataset menjadi data training dan data testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Tweet'], df['Sentimen'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Melatih model Naive Bayes Classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Melakukan transform pada data testing\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Melakukan prediksi sentimen\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# Menghitung akurasi model\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "# Menampilkan hasil akurasi\n",
        "print(\"Akurasi model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "mipGC8B7yYii",
        "outputId": "843342e8-c80c-414a-869e-5332d96d7c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sentimen'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-90e7c14fa84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Membagi dataset menjadi data training dan data testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentimen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Mengubah teks menjadi vektor fitur numerik menggunakan TfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sentimen'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca dataset\n",
        "df_test = pd.read_csv(\"sentimen_hasil.csv\")\n",
        "\n",
        "# Preprocessing tweet\n",
        "def preprocess_tweet(tweet):\n",
        "    # Menghapus karakter non-angka/non-huruf\n",
        "    tweet = re.sub('[^a-zA-Z0-9]', ' ', tweet)\n",
        "    # Mengubah semua huruf menjadi lowercase\n",
        "    tweet = tweet.lower()\n",
        "    return tweet\n",
        "\n",
        "# Menerapkan preprocessing pada tweet\n",
        "df_test['Tweet'] = df_test['Tweet'].apply(preprocess_tweet)\n",
        "\n",
        "# Menghitung rata-rata likes, replies, dan retweets\n",
        "mean_likes = df_test['Likes'].mean()\n",
        "mean_replies = df_test['Replies'].mean()\n",
        "mean_retweets = df_test['Retweets'].mean()\n",
        "\n",
        "# Menandai tweet yang memiliki like, reply, atau retweet di atas rata-rata sebagai sentimen positif\n",
        "df_test['Sentimen'] = np.where((df_test['Likes'] > mean_likes) | (df_test['Replies'] > mean_replies) | (df_test['Retweets'] > mean_retweets), 'positif', 'negatif')\n",
        "\n",
        "# Memisahkan dataset menjadi data training dan data testing\n",
        "train_df = df_test.sample(frac=0.9, random_state=1)\n",
        "test_df = df_test.drop(train_df.index)\n",
        "\n",
        "# Membuat objek TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Melakukan fitting dan transform pada data training\n",
        "X_train = vectorizer.fit_transform(train_df['Tweet'])\n",
        "y_train = train_df['Sentimen']\n",
        "\n",
        "# Melakukan transform pada data testing\n",
        "X_test = vectorizer.transform(test_df['Tweet'])\n",
        "y_test = test_df['Sentimen']\n",
        "\n",
        "# Melatih model Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "hZvS7g2vCdpN",
        "outputId": "008ff4dd-53e2-4d2e-b2a5-c417d1a8ffa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f91d7ceabb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Membaca dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentimen_hasil.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Preprocessing tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentimen_hasil.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah teks menjadi vektor fitur numerik menggunakan TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "YxoIAbLKymy9",
        "outputId": "f71567b9-53f6-470a-f97a-41bbf81338f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1dcd88ecafcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mengubah teks menjadi vektor fitur numerik menggunakan TfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing tweet\n",
        "def preprocess_tweet(tweet):\n",
        "    # Menghapus karakter non-angka/non-huruf\n",
        "    tweet = re.sub('[^a-zA-Z0-9]', ' ', tweet)\n",
        "    # Mengubah semua huruf menjadi lowercase\n",
        "    tweet = tweet.lower()\n",
        "    return tweet\n",
        "\n",
        "# Menerapkan preprocessing pada tweet\n",
        "df['Tweet'] = df['Tweet'].apply(preprocess_tweet)\n",
        "\n",
        "# Melakukan transform pada data testing\n",
        "X_test = vectorizer.transform(df['Tweet'])\n",
        "\n",
        "# Melakukan prediksi sentimen\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# Menambahkan kolom sentimen pada dataset\n",
        "df['Sentimen'] = y_pred\n",
        "\n",
        "# Menyimpan dataset dengan kolom sentimen baru\n",
        "df.to_csv(\"sentimen_hasil.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "pu2d-EqawZUo",
        "outputId": "3d9f00a3-2bf1-4fcb-da16-5bf5e5079ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6e427c1126df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Melakukan transform pada data testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Melakukan prediksi sentimen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memprediksi sentimen pada data testing\n",
        "y_pred = nb.predict(X_test)"
      ],
      "metadata": {
        "id": "CMTBsaELEo48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung nilai akurasi, presisi, recall, dan f1-score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label='positif')\n",
        "recall = recall_score(y_test, y_pred, pos_label='positif')\n",
        "f1 = f1_score(y_test, y_pred, pos_label='positif')\n",
        "\n",
        "# Mencetak hasil evaluasi\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpWeE2NEJ7f",
        "outputId": "76fe9b14-79d4-4d28-9b10-b6366411d583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.78\n",
            "Precision: 0.75\n",
            "Recall: 0.125\n",
            "F1-score: 0.21428571428571427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "uKNWFiwyYl8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}